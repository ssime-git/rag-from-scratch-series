{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with PDF using Langchain\n",
    "\n",
    "## Step 1: Import the necessary libraries and instantiate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries and models setup\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.retrievers import SelfQueryRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the ` AzureChatOpenAI` and `AzureOpenAIEmbeddings` models as previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat Model definition\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=\"2023-09-01-preview\",\n",
    "    azure_endpoint=os.getenv('AZURE_API_ENDPOINT'),\n",
    "    api_key=os.getenv('AZURE_OPENAI_KEY'),\n",
    "    azure_deployment=os.getenv('OPENAI_DEPLOYMENT_NAME'),\n",
    "    model_name=os.getenv('OPENAI_MODEL_NAME'),\n",
    "    model_version=os.getenv('OPENAI_API_VERSION'),\n",
    "    temperature=.7\n",
    ")\n",
    "\n",
    "# Embeddings model definition\n",
    "embedding_model = AzureOpenAIEmbeddings(\n",
    "    openai_api_version=\"2023-09-01-preview\",\n",
    "    azure_endpoint=os.getenv('AZURE_API_ENDPOINT'),\n",
    "    api_key=os.getenv('AZURE_OPENAI_KEY'),\n",
    "    azure_deployment=os.getenv('OPENAI_DEPLOYMENT_NAME_EMBEDDING')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the data from the PDF\n",
    "\n",
    "Use the function `PyPDFLoader` to load the PDF file from the `data`folder. Note that once the function instantiated with the file path, you can use the `load` method to load the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your PDF file\n",
    "pdf_file_path = 'data/2005.11401v4.pdf'\n",
    "\n",
    "# Create a loader instance\n",
    "loader = PyPDFLoader(pdf_file_path)\n",
    "\n",
    "# Load the data from the PDF\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Split the PDF content into smaller chunks\n",
    "\n",
    "Use the function `RecursiveCharacterTextSplitter` function with the following parameters `chunk_size=1000, chunk_overlap=150`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "\n",
    "# Split the PDF content into smaller chunks\n",
    "docs = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create a Chroma vector store to store the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to store the Chroma database\n",
    "db_path = \"./\"\n",
    "\n",
    "# Create a Chroma vector store\n",
    "chroma_db = Chroma.from_documents(docs, embedding_model, persist_directory=db_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Retrieve relevant documents (RETRIEVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Jonathan Berant. Coarse-to-ﬁne question answering for long documents. In Proceedings of the\\n55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) ,\\npages 209–220, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi:\\n10.18653/v1/P17-1020. URL https://www.aclweb.org/anthology/P17-1020 .\\n10', metadata={'page': 9, 'source': 'data/2005.11401v4.pdf'}),\n",
       " Document(page_content='Processing , pages 3950–3959, Brussels, Belgium, October-November 2018. Association for\\nComputational Linguistics. doi: 10.18653/v1/D18-1429. URL https://www.aclweb.org/\\nanthology/D18-1429 .\\n[43] Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder,\\nand Li Deng. MS MARCO: A human generated machine reading comprehension dataset. In\\nTarek Richard Besold, Antoine Bordes, Artur S. d’Avila Garcez, and Greg Wayne, editors,\\nProceedings of the Workshop on Cognitive Computation: Integrating neural and symbolic\\n13', metadata={'page': 12, 'source': 'data/2005.11401v4.pdf'}),\n",
       " Document(page_content='[7]Christopher Clark and Matt Gardner. Simple and Effective Multi-Paragraph Reading Compre-\\nhension. arXiv:1710.10723 [cs] , October 2017. URL http://arxiv.org/abs/1710.10723 .\\narXiv: 1710.10723.\\n[8]Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of\\nDeep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Con-\\nference of the North American Chapter of the Association for Computational Linguistics: Human\\nLanguage Technologies, Volume 1 (Long and Short Papers) , pages 4171–4186, Minneapolis,\\nMinnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423.\\nURL https://www.aclweb.org/anthology/N19-1423 .\\n[9]Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason Weston. Wiz-\\nard of wikipedia: Knowledge-powered conversational agents. In International Conference on\\nLearning Representations , 2019. URL https://openreview.net/forum?id=r1l73iRqKm .', metadata={'page': 10, 'source': 'data/2005.11401v4.pdf'}),\n",
       " Document(page_content='with \"The SunAlso Rises\" isanovel bythis author of\"AFarewell toArms\" . This example shows\\nhow parametric and non-parametric memories work together —the non-parametric component helps\\nto guide the generation, drawing out speciﬁc knowledge stored in the parametric memory.\\n4.4 Fact Veriﬁcation\\nTable 2 shows our results on FEVER. For 3-way classiﬁcation, RAG scores are within 4.3% of\\nstate-of-the-art models, which are complex pipeline systems with domain-speciﬁc architectures and\\nsubstantial engineering, trained using intermediate retrieval supervision, which RAG does not require.\\n6', metadata={'page': 5, 'source': 'data/2005.11401v4.pdf'})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a retriever object using Chroma\n",
    "retriever = chroma_db.as_retriever()\n",
    "\n",
    "# Search for relevant documents based on a user query\n",
    "query = \"What is the topic of the PDF?\"\n",
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Perform RAG using RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What is the main topic discussed in the PDF?', 'result': 'The main topic discussed in the PDF is the Retrieval-Augmented Generation (RAG) model, which is a combination of a parametric neural network and a non-parametric memory. The PDF presents the design and evaluation of RAG in the context of natural language generation and fact verification tasks, with a focus on its ability to generate coherent and plausible text while also being able to verify the truthfulness of the generated information. Results are presented for various benchmarks, including the FEVER dataset, where RAG achieves competitive performance compared to state-of-the-art models without requiring intermediate retrieval supervision.'}\n"
     ]
    }
   ],
   "source": [
    "# Create a retriever object with specific search configurations\n",
    "retriever = chroma_db.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# Create a RetrievalQA instance\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False\n",
    ")\n",
    "\n",
    "# Call the RAG chain with a user query\n",
    "question = \"What is the main topic discussed in the PDF?\"\n",
    "response = rag_chain.invoke({\"query\": question})\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
